{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸï¸ F1 Dashboard\n",
    "\n",
    "**Owner** ğŸ‘¨â€ğŸ’»: Matheus Rodrigues </br>\n",
    "**Status** ğŸš¦: In Progress </br>\n",
    "**Description** ğŸ“–: A dashboard to analyze Formula 1 data, consuming fastf1 API. <br/>\n",
    "**Last Update** ğŸ“… : 2026-02-18 <br/>\n",
    "___\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: '../requirements.txt'\n",
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install dependencies\n",
    "%pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fbc454ef-de54-491a-9b10-4363a8c02d44",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from pyspark.sql import SparkSession\n",
    "from matplotlib import pyplot as plt\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import fastf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No Spark session found. Assuming local environment.\n"
     ]
    }
   ],
   "source": [
    "# Check if running in Databricks environment\n",
    "try:\n",
    "    spark\n",
    "    print(\"Spark session already exists.\")\n",
    "    IS_DATABRICKS = True\n",
    "except NameError:\n",
    "    print(\"No Spark session found. Assuming local environment.\")\n",
    "    IS_DATABRICKS = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark session created successfully.\n"
     ]
    }
   ],
   "source": [
    "# Create Spark session if not in Databricks\n",
    "if not IS_DATABRICKS:\n",
    "    try:\n",
    "        spark = SparkSession.builder\\\n",
    "            .appName(\"F1_Analytics\")\\\n",
    "            .master(\"local[*]\")\\\n",
    "            .getOrCreate()\n",
    "        print(\"Spark session created successfully.\")\n",
    "    except ImportError:\n",
    "        print(\"PySpark is not installed. Please install PySpark to use Spark features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define variables\n",
    "years = [2023, 2024, 2025]\n",
    "circuits = ['Monza', 'Silverstone', 'Spa-Francorchamps', 'Suzuka', 'Interlagos']\n",
    "sessions = ['FP1', 'FP2', 'FP3', 'Q', 'Race']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "req         WARNING \tDEFAULT CACHE ENABLED! (48.34 MB) C:\\Users\\mathe\\AppData\\Local\\Temp\\fastf1\n"
     ]
    }
   ],
   "source": [
    "# Create a dataframe of circuits and their locations\n",
    "circuits_df = []\n",
    "for year in years:\n",
    "    schedule = fastf1.get_event_schedule(year)\n",
    "    df_schedule = pd.DataFrame(schedule)\n",
    "\n",
    "    circuits_df.append(df_schedule)\n",
    "\n",
    "\n",
    "final_circuits_df = pd.concat(circuits_df, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'get_session_date'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Create a dataframe of \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m session = \u001b[43mfastf1\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcore\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSession\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFrench Grand Prix\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mQ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m session.load()\n\u001b[32m      5\u001b[39m session.results\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\projects\\analytics-monitor-f1\\.venv\\Lib\\site-packages\\fastf1\\core.py:1174\u001b[39m, in \u001b[36mSession.__init__\u001b[39m\u001b[34m(self, event, session_name, f1_api_support)\u001b[39m\n\u001b[32m   1171\u001b[39m \u001b[38;5;28mself\u001b[39m.f1_api_support = f1_api_support\n\u001b[32m   1172\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"bool: The official F1 API supports this event and lap timing\u001b[39;00m\n\u001b[32m   1173\u001b[39m \u001b[33;03mdata and telemetry data are available.\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1174\u001b[39m \u001b[38;5;28mself\u001b[39m.date = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mevent\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_session_date\u001b[49m(session_name, utc=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m   1175\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"pandas.Datetime: Date at which this session took place.\"\"\"\u001b[39;00m\n\u001b[32m   1177\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'get_session_date'"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": ".venv (3.11.5)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
